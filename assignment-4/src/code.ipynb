{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # processing file path\n",
    "import gzip # unzip the .gz file, not used here\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data,shuf):\n",
    "    X = data.loc[0:, data.columns != 'label']\n",
    "    Y = data.loc[0:, 'label']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(  X, Y, test_size = 0,shuffle=shuf)\n",
    "    return X, Y, X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Apparel/apparel-trainval.csv',sep= ',')\n",
    "X, Y, X_train, X_test, y_train, y_test = split_dataset(df,True)\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "mask = list(range(59000, 59000 + 1000))\n",
    "X_val = X_train[mask]\n",
    "X_val = X_val.reshape(1000, -1)\n",
    "y_val = y_train[mask]\n",
    "mask = list(range(59000))\n",
    "X_train = X_train[mask]\n",
    "X_train = X_train.reshape(59000, -1)\n",
    "y_train = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):    \n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):    \n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(object):    \n",
    "    def __init__(self, input_size, hidden_size, output_size, std=1e-4): \n",
    "        self.params = {}\n",
    "        sz1 = np.random.randn(input_size, hidden_size)\n",
    "        sz2 = np.random.randn(hidden_size, output_size)\n",
    "        sz3 = np.zeros((1, hidden_size))  \n",
    "        sz4 = np.zeros((1, output_size))\n",
    "        self.params['W1'] = std * sz1\n",
    "        self.params['W2'] = std * sz2   \n",
    "        self.params['b1'] = sz3    \n",
    "        self.params['b2'] = sz4\n",
    "\n",
    "    def loss(self, X, y=None, reg=0.0):\n",
    "        N, D = X.shape\n",
    "        scores = None\n",
    "        W2 = self.params['W2']\n",
    "        b2 = self.params['b2']\n",
    "        W1 = self.params['W1']\n",
    "        b1 = self.params['b1']\n",
    "        ddt = np.dot(X, W1) + b1\n",
    "        h1 = ReLU(ddt)\n",
    "        ddt = np.dot(h1, W2)\n",
    "        scores = ddt + b2 \n",
    "        \n",
    "        if y is None:   \n",
    "            return scores\n",
    "        \n",
    "        scores_max = np.max(scores, axis=1, keepdims=True)    \n",
    "        exp_scores = np.exp(scores - scores_max)\n",
    "        \n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)    \n",
    "        correct_logprobs = -np.log(probs[range(N), y])        \n",
    "        data_loss = np.sum(correct_logprobs)\n",
    "        data_loss = data_loss / N\n",
    "        ww1 = np.sum(W1*W1)\n",
    "        ww2 = np.sum(W2*W2)\n",
    "        loss = data_loss + 0.5 * reg * ww1 + 0.5 * reg * ww2\n",
    "        \n",
    "        grads = {}\n",
    "        dscores = probs                                 \n",
    "        dscores[range(N), y] -= 1\n",
    "        dscores /= N\n",
    "        db2 = np.sum(dscores, axis=0, keepdims=True)    \n",
    "        dh1 = np.dot(dscores, W2.T)                     \n",
    "        dh1[h1 <= 0] = 0\n",
    "        \n",
    "        grads['W1'] = np.dot(X.T, dh1) + reg * W1\n",
    "        grads['W2'] = np.dot(h1.T, dscores) + reg * W2 \n",
    "        grads['b1'] = np.sum(dh1, axis=0, keepdims=True)\n",
    "        grads['b2'] = db2\n",
    "\n",
    "        return loss, grads\n",
    "\n",
    "    def train(self, X, y, X_val, y_val, learning_rate=1e-3, \n",
    "               learning_rate_decay=0.95, reg=1e-5, num_epochs=10, \n",
    "               batch_size=200, verbose = False):   \n",
    "        num_train = X.shape[0]\n",
    "        iterations_per_epoch = max(int(num_train / batch_size), 1)\n",
    "        \n",
    "        v_W1, v_b1 = 0.0, 0.0\n",
    "        v_W2, v_b2 = 0.0, 0.0\n",
    "        lsh = []\n",
    "        train_acc_history = []\n",
    "        val_acc_history = []\n",
    "        \n",
    "        rng = num_epochs * iterations_per_epoch + 1\n",
    "        \n",
    "        for it in range(1, rng):   \n",
    "            y_batch = None \n",
    "            X_batch = None   \n",
    "\n",
    "            sample_index = np.random.choice(num_train, batch_size, replace=True)   \n",
    "            X_batch = X[sample_index, :]          \n",
    "            y_batch = y[sample_index]             \n",
    "            \n",
    "            loss, grads = self.loss(X_batch, y=y_batch, reg=reg) \n",
    "            lsh.append(loss)\n",
    "            tt1 = learning_rate * grads['W2'] \n",
    "            v_W2 = 0.9 * v_W2 - tt1    \n",
    "            self.params['W2'] += 0.9 * v_W2 - tt1\n",
    "            tt2 = learning_rate * grads['b2']\n",
    "            self.params['b2'] += 0.9 * v_b2 - tt2 \n",
    "            tt3 = learning_rate * grads['b1']\n",
    "            self.params['b1'] += 0.9 * v_b1 - tt3\n",
    "            tt4 = learning_rate * grads['W1']\n",
    "            v_W1 = 0.9 * v_W1 - tt4   \n",
    "            self.params['W1'] += v_W1   \n",
    "\n",
    "            if verbose == True and it % iterations_per_epoch == 0:\n",
    "                tmp = iterations_per_epoch\n",
    "                train_acc = (self.predict(X_batch) == y_batch).mean()    \n",
    "                val_acc = (self.predict(X_val) == y_val).mean()    \n",
    "                train_acc_history.append(train_acc)    \n",
    "                val_acc_history.append(val_acc) \n",
    "                epoch = it / tmp    \n",
    "                learning_rate *= learning_rate_decay\n",
    "\n",
    "        return {\n",
    "            'train_acc_history': train_acc_history,   \n",
    "            'lsh': lsh,   \n",
    "            'val_acc_history': val_acc_history,\n",
    "        }\n",
    "\n",
    "    def predict(self, X):    \n",
    "        y_pred = None\n",
    "        ddt = np.dot(X, self.params['W1']) + self.params['b1']\n",
    "        h1 = ReLU(ddt)\n",
    "        ddt1 = np.dot(h1, self.params['W2'])\n",
    "        scrs =  ddt1 + self.params['b2']\n",
    "        y_pred = np.argmax(scrs, axis=1)    \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10: loss 0.891100, train_acc: 0.710938, val_acc: 0.706000\n",
      "epoch 2 / 10: loss 0.657148, train_acc: 0.801758, val_acc: 0.788000\n",
      "epoch 3 / 10: loss 0.661734, train_acc: 0.825195, val_acc: 0.837000\n",
      "epoch 4 / 10: loss 0.594684, train_acc: 0.832031, val_acc: 0.832000\n",
      "epoch 5 / 10: loss 0.597808, train_acc: 0.834961, val_acc: 0.850000\n",
      "epoch 6 / 10: loss 0.523818, train_acc: 0.857422, val_acc: 0.845000\n",
      "epoch 7 / 10: loss 0.546911, train_acc: 0.852539, val_acc: 0.849000\n",
      "epoch 8 / 10: loss 0.595983, train_acc: 0.833984, val_acc: 0.859000\n",
      "epoch 9 / 10: loss 0.591881, train_acc: 0.837891, val_acc: 0.844000\n",
      "epoch 10 / 10: loss 0.538394, train_acc: 0.861328, val_acc: 0.855000\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNet(X_train.shape[1], 10, 10)\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_epochs=10, batch_size=1024,\n",
    "            learning_rate=7.5e-4, learning_rate_decay=0.95,\n",
    "            reg=1.0, verbose = True)\n",
    "\n",
    "predict_val = net.predict(X_val)\n",
    "cnt = 0\n",
    "for i in range(len(predict_val)):\n",
    "    if predict_val[i]==y_val[i]:\n",
    "        cnt = cnt + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8503204465577837\n"
     ]
    }
   ],
   "source": [
    "givendataset = pd.read_csv('Apparel/apparel-test.csv')\n",
    "testdataset = pd.read_csv('input/fashion-mnist_test.csv')\n",
    "testdataset.drop(testdataset.tail(326).index,inplace=True)\n",
    "X, Y, X_test, tmp1, y_test, tmp2 = split_dataset(testdataset,False)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "test_acc = (best_net.predict(X_test) == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 2.500000e-04 reg 2.500000e-01 val accuracy: 0.849000\n",
      "lr 2.500000e-04 reg 5.000000e-01 val accuracy: 0.852000\n",
      "lr 2.500000e-04 reg 7.500000e-01 val accuracy: 0.850000\n",
      "lr 2.500000e-04 reg 1.000000e+00 val accuracy: 0.841000\n",
      "lr 5.000000e-04 reg 2.500000e-01 val accuracy: 0.846000\n",
      "lr 5.000000e-04 reg 5.000000e-01 val accuracy: 0.851000\n",
      "lr 5.000000e-04 reg 7.500000e-01 val accuracy: 0.847000\n",
      "lr 5.000000e-04 reg 1.000000e+00 val accuracy: 0.848000\n",
      "lr 7.500000e-04 reg 2.500000e-01 val accuracy: 0.843000\n",
      "lr 7.500000e-04 reg 5.000000e-01 val accuracy: 0.807000\n",
      "lr 7.500000e-04 reg 7.500000e-01 val accuracy: 0.783000\n",
      "lr 7.500000e-04 reg 1.000000e+00 val accuracy: 0.838000\n",
      "lr 1.000000e-03 reg 2.500000e-01 val accuracy: 0.465000\n",
      "lr 1.000000e-03 reg 5.000000e-01 val accuracy: 0.519000\n",
      "lr 1.000000e-03 reg 7.500000e-01 val accuracy: 0.825000\n",
      "lr 1.000000e-03 reg 1.000000e+00 val accuracy: 0.788000\n",
      "best validation accuracy achieved during cross-validation: 0.852000\n"
     ]
    }
   ],
   "source": [
    "# hidden_size = 10\n",
    "# num_classes = 10\n",
    "# results = {}\n",
    "# best_val = -1\n",
    "# best_net = None\n",
    "\n",
    "# learning_rates = np.array([2.5,5,7.5,10])*1e-4\n",
    "# regularization_strengths = [0.25,0.5,0.75,1]\n",
    "\n",
    "# for lr in learning_rates:\n",
    "#     for reg in regularization_strengths:\n",
    "#         net = NeuralNet(input_size, hidden_size, num_classes)\n",
    "#         stats = net.train(X_train, y_train, X_val, y_val,\n",
    "#         num_epochs=10, batch_size=1024,\n",
    "#         learning_rate=lr, learning_rate_decay=0.95,\n",
    "#         reg= reg, verbose=False)\n",
    "#         val_acc = (net.predict(X_val) == y_val).mean()\n",
    "#         if val_acc > best_val:\n",
    "#             best_val = val_acc\n",
    "#             best_net = net         \n",
    "#         results[(lr,reg)] = val_acc\n",
    "\n",
    "\n",
    "# for lr, reg in sorted(results):\n",
    "#     val_acc = results[(lr, reg)]\n",
    "#     print('lr %e reg %e val accuracy: %f' % (\n",
    "#                 lr, reg,  val_acc))\n",
    "    \n",
    "# print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "pred = best_net.predict(X_test)\n",
    "for val in pred:\n",
    "    arr.append([val])\n",
    "np.savetxt(\"20161005_apparel_prediction5.csv\", arr, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = []\n",
    "for val in y_test:\n",
    "    tmp2.append([val])\n",
    "np.savetxt(\"tmp2.csv\", tmp2, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppf1 = pd.read_csv('20161005_apparel_prediction5.csv')\n",
    "ppf1 = np.asarray(ppf1)\n",
    "\n",
    "ppf2 = pd.read_csv('tmp2.csv')\n",
    "ppf2 = np.asarray(ppf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(ppf1)):\n",
    "    if(ppf1[i]!=ppf2[i]):\n",
    "        cnt = cnt + 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.asarray(givendataset)\n",
    "arr = []\n",
    "pred = best_net.predict(X_test2)\n",
    "for val in pred:\n",
    "    arr.append([val])\n",
    "np.savetxt(\"20161005_apparel_prediction6.csv\", arr, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
